{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda4a601-5ca3-411f-b56c-b37dd4dd7155",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e36cf5-8af6-48e1-aa68-191a872abdb0",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical test used to determine if there are significant differences between the means of three or more independent groups. For ANOVA results to be valid, several key assumptions must be met. If these assumptions are violated, the validity of the results can be compromised. The assumptions are:\n",
    "\n",
    "### 1. **Independence of Observations**\n",
    "   - **Assumption**: The data points (observations) in each group must be independent of each other. This means the value of one observation should not influence or be influenced by the value of another observation.\n",
    "   - **Example of Violation**: A violation of this assumption can occur if the same subjects are included in multiple groups (repeated measures), or if subjects within a group are related or influence each other (e.g., family members or co-workers).\n",
    "   - **Impact**: Lack of independence can lead to underestimated variability within groups, inflating the F-ratio and increasing the risk of false positives (Type I errors).\n",
    "\n",
    "### 2. **Normality**\n",
    "   - **Assumption**: The residuals (differences between observed and expected values) for each group should follow a normal distribution. This is most important when sample sizes are small.\n",
    "   - **Example of Violation**: If the data is heavily skewed or contains extreme outliers, the assumption of normality is violated. For example, income data often violates normality due to large variations in wealth.\n",
    "   - **Impact**: If the normality assumption is violated, the ANOVA may yield inaccurate p-values. However, ANOVA is robust to moderate violations of normality, especially with larger sample sizes (Central Limit Theorem).\n",
    "\n",
    "### 3. **Homogeneity of Variances (Homoscedasticity)**\n",
    "   - **Assumption**: The variance (spread) of the residuals should be approximately equal across all groups.\n",
    "   - **Example of Violation**: A violation of this assumption occurs if one group has much higher variance than others. For example, in an experiment measuring performance under different levels of stress, one group may have highly variable responses compared to others.\n",
    "   - **Impact**: Unequal variances can distort the F-statistic and lead to incorrect conclusions. This violation is particularly problematic when sample sizes are unequal across groups (heteroscedasticity).\n",
    "\n",
    "### 4. **Random Sampling**\n",
    "   - **Assumption**: The data should be collected through random sampling, ensuring that the sample represents the population being studied.\n",
    "   - **Example of Violation**: A violation occurs if the sample is not randomly selected, for instance, if a study on consumer preferences is conducted by only surveying people from one neighborhood or demographic.\n",
    "   - **Impact**: Non-random sampling can lead to biased results that do not accurately reflect the population, affecting the generalizability of the results.\n",
    "\n",
    "### Violations and Remedies:\n",
    "- **Independence Violation**: Use a repeated measures ANOVA or mixed-effects models if observations are related.\n",
    "- **Normality Violation**: Apply data transformation (e.g., log or square root transformations), or use a non-parametric alternative like the Kruskal-Wallis test.\n",
    "- **Homogeneity of Variances Violation**: Use Welch’s ANOVA, which does not assume equal variances, or apply a correction like the Brown-Forsythe test.\n",
    "\n",
    "### Conclusion:\n",
    "Violating these assumptions can undermine the validity of ANOVA results, leading to incorrect conclusions about group differences. Careful attention to the assumptions and appropriate statistical adjustments can mitigate the effects of these violations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e74a27-c3f7-4b81-b916-93c53a5183cb",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5a53a1-0f30-46de-9837-920e45974867",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a powerful statistical method used to test for differences among group means in various situations. There are three main types of ANOVA, each designed for specific experimental designs or data structures. Here are the three types and the situations in which each is used:\n",
    "\n",
    "### 1. **One-Way ANOVA (Single-Factor ANOVA)**\n",
    "   - **Description**: One-way ANOVA is used to compare the means of three or more independent groups based on a single independent variable (factor). This test determines whether there are statistically significant differences between the group means.\n",
    "   - **When to Use**: \n",
    "     - When there is **one categorical independent variable** (factor) with **two or more levels** (groups).\n",
    "     - The dependent variable should be continuous (e.g., weight, score, time).\n",
    "     - Example: A researcher wants to compare the average test scores of students from three different schools (School A, School B, School C) to determine if the school attended has an effect on test performance.\n",
    "   - **Hypotheses**:\n",
    "     - Null Hypothesis (\\(H_0\\)): The means of all groups are equal.\n",
    "     - Alternative Hypothesis (\\(H_a\\)): At least one group mean is different from the others.\n",
    "\n",
    "### 2. **Two-Way ANOVA (Factorial ANOVA)**\n",
    "   - **Description**: Two-way ANOVA is used to compare group means when there are **two independent variables (factors)**. It allows you to evaluate the individual and interaction effects of the two factors on the dependent variable.\n",
    "   - **When to Use**: \n",
    "     - When you have **two independent variables**, each with two or more levels, and a **continuous dependent variable**.\n",
    "     - You can assess both **main effects** (the effect of each independent variable on its own) and **interaction effects** (whether the effect of one independent variable depends on the level of the other variable).\n",
    "     - Example: A researcher wants to investigate the effect of both **diet type** (vegetarian, vegan, omnivore) and **exercise frequency** (low, moderate, high) on weight loss. Two-way ANOVA will help determine if these factors individually or interactively affect weight loss.\n",
    "   - **Hypotheses**:\n",
    "     - Null Hypothesis (\\(H_0\\)): The means for each factor and their interaction are equal across groups.\n",
    "     - Alternative Hypothesis (\\(H_a\\)): At least one factor or their interaction significantly affects the dependent variable.\n",
    "\n",
    "### 3. **Repeated Measures ANOVA**\n",
    "   - **Description**: Repeated measures ANOVA is used when the same subjects are measured multiple times under different conditions or over time. This test accounts for the **within-subject correlation** (i.e., the fact that multiple observations from the same subject are related) and compares the means across different time points or conditions.\n",
    "   - **When to Use**: \n",
    "     - When you have a **within-subject design**, where each subject is exposed to all levels of the independent variable.\n",
    "     - The repeated measurements could be over time (e.g., measuring the effect of a drug at multiple time points) or under different conditions (e.g., different tasks performed by the same individuals).\n",
    "     - Example: A clinical trial measures the blood pressure of patients at three different time points (baseline, 1 month, 3 months) after starting a new medication. Since the same patients are measured at each time point, a repeated measures ANOVA is appropriate to assess if there is a significant change over time.\n",
    "   - **Hypotheses**:\n",
    "     - Null Hypothesis (\\(H_0\\)): The mean responses at each time point (or condition) are equal.\n",
    "     - Alternative Hypothesis (\\(H_a\\)): The mean responses at different time points (or conditions) are not equal.\n",
    "\n",
    "### Situations for Each Type of ANOVA:\n",
    "\n",
    "1. **One-Way ANOVA**: Use when you have a single factor with multiple groups and you want to compare the means across these groups.\n",
    "   - **Example**: Testing if different diets lead to different average weight loss in three separate groups.\n",
    "   \n",
    "2. **Two-Way ANOVA**: Use when you have two factors and want to assess the individual and combined effects of those factors.\n",
    "   - **Example**: Investigating the effect of both **diet type** and **exercise level** on weight loss.\n",
    "\n",
    "3. **Repeated Measures ANOVA**: Use when you measure the same subjects multiple times, either across time or under different conditions.\n",
    "   - **Example**: Assessing the impact of a training program on performance, measured at three different time intervals for the same group of individuals.\n",
    "\n",
    "### Summary Table:\n",
    "\n",
    "| **ANOVA Type**           | **Factors**     | **Use Case** | **Example** |\n",
    "|--------------------------|-----------------|--------------|-------------|\n",
    "| **One-Way ANOVA**         | 1 (Single factor) | Compare means of different groups | Compare exam scores across three schools |\n",
    "| **Two-Way ANOVA**         | 2 (Factorial)   | Compare means across two factors and their interaction | Compare diet and exercise on weight loss |\n",
    "| **Repeated Measures ANOVA** | 1 (Repeated measures) | Same subjects measured over time or conditions | Measure blood pressure at multiple time points |\n",
    "\n",
    "Each type of ANOVA is suited for different experimental designs, allowing you to assess multiple factors or time-based changes efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70482099-d84e-4f6d-8d7e-a183af3e54d0",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfcf5e5-fcf8-4cc1-8baa-bb8d0dbd0045",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA (Analysis of Variance) refers to dividing the total variability in the data into different components to identify the sources of variation. This concept is fundamental because it helps to determine whether the differences between group means are due to the experimental factor(s) or merely random noise (within-group variation). Understanding how variance is partitioned is key to interpreting ANOVA results.\n",
    "\n",
    "### Components of Variance in ANOVA\n",
    "\n",
    "In ANOVA, the total variability in the data is broken down into two main components:\n",
    "\n",
    "1. **Between-Group Variance (Explained Variance)**:\n",
    "   - This represents the variability **due to differences between the group means**. It captures how much of the total variability is explained by the independent variable (factor). If the group means are far apart, the between-group variance will be large.\n",
    "   - In other words, it reflects the variability **caused by the effect of the independent variable**.\n",
    "   - Example: If we are comparing test scores of students from three different schools, the between-group variance measures the differences in average scores between the schools.\n",
    "\n",
    "2. **Within-Group Variance (Unexplained Variance, Error Variance)**:\n",
    "   - This represents the variability **within each group**. It measures how much the individual observations vary within each group around their respective group mean.\n",
    "   - This component reflects the random variability or noise that is not explained by the independent variable.\n",
    "   - Example: In the same test score comparison, within-group variance measures how much test scores vary among students within each school, unrelated to the difference in schools.\n",
    "\n",
    "3. **Total Variance**:\n",
    "   - The total variance represents the overall variability in the dataset, combining both between-group and within-group variance. It reflects the total amount of variation among all observations, without considering group membership.\n",
    "   - Mathematically, it is the sum of the between-group variance and the within-group variance.\n",
    "\n",
    "### Partitioning Variance in ANOVA\n",
    "\n",
    "The partitioning of variance in ANOVA can be expressed as:\n",
    "\n",
    "\\[\n",
    "\\text{Total Sum of Squares (SST)} = \\text{Between-Group Sum of Squares (SSB)} + \\text{Within-Group Sum of Squares (SSW)}\n",
    "\\]\n",
    "\n",
    "- **Total Sum of Squares (SST)**: Measures the total variation in the data, considering all observations regardless of group membership.\n",
    "  \\[\n",
    "  SST = \\sum (\\text{Observation} - \\text{Overall Mean})^2\n",
    "  \\]\n",
    "\n",
    "- **Between-Group Sum of Squares (SSB)**: Measures the variation **between group means**. It quantifies how much group means differ from the overall mean.\n",
    "  \\[\n",
    "  SSB = \\sum (\\text{Group Mean} - \\text{Overall Mean})^2 \\times \\text{Group Size}\n",
    "  \\]\n",
    "\n",
    "- **Within-Group Sum of Squares (SSW)**: Measures the variation **within groups**, i.e., how much individual observations within a group differ from their group mean.\n",
    "  \\[\n",
    "  SSW = \\sum (\\text{Observation} - \\text{Group Mean})^2\n",
    "  \\]\n",
    "\n",
    "### Importance of Partitioning of Variance in ANOVA\n",
    "\n",
    "1. **F-Ratio Calculation**:\n",
    "   - The partitioning of variance is crucial for calculating the **F-ratio**, which is the test statistic in ANOVA. The F-ratio is computed as the ratio of **between-group variance** (SSB) to **within-group variance** (SSW):\n",
    "   \\[\n",
    "   F = \\frac{\\text{Mean Square Between Groups (MSB)}}{\\text{Mean Square Within Groups (MSW)}}\n",
    "   \\]\n",
    "   - If the between-group variance is significantly larger than the within-group variance, the F-ratio will be large, suggesting that the differences between group means are unlikely due to chance and are statistically significant.\n",
    "\n",
    "2. **Testing Hypotheses**:\n",
    "   - The goal of ANOVA is to test whether the group means are significantly different. Partitioning variance helps isolate the effect of the independent variable(s) by comparing the between-group variance (explained by the factor) with the within-group variance (random noise or error).\n",
    "   - **Null Hypothesis (\\(H_0\\))**: The group means are equal (i.e., the between-group variance is small relative to the within-group variance).\n",
    "   - **Alternative Hypothesis (\\(H_a\\))**: At least one group mean is different (i.e., the between-group variance is significantly larger than the within-group variance).\n",
    "\n",
    "3. **Identifying the Source of Variation**:\n",
    "   - Partitioning variance helps us understand where the variation in the data is coming from:\n",
    "     - **Large Between-Group Variance**: Suggests that the factor being tested has a significant effect on the dependent variable.\n",
    "     - **Large Within-Group Variance**: Suggests that there is a lot of variability within groups that is not explained by the factor being tested, possibly indicating measurement errors or uncontrolled variables.\n",
    "\n",
    "4. **ANOVA Table**:\n",
    "   - The results of ANOVA are typically presented in an **ANOVA table**, where the partitioned variance (SSB and SSW) is used to calculate the mean squares (MSB and MSW), the F-ratio, and the corresponding p-value. Understanding the partitioning of variance allows you to interpret the ANOVA table accurately.\n",
    "\n",
    "| Source of Variation | Sum of Squares | Degrees of Freedom | Mean Square | F-Ratio |\n",
    "|---------------------|----------------|--------------------|-------------|---------|\n",
    "| Between Groups       | SSB            | \\(k - 1\\)          | MSB = SSB / \\(k - 1\\) | \\(F = \\frac{\\text{MSB}}{\\text{MSW}}\\) |\n",
    "| Within Groups        | SSW            | \\(n - k\\)          | MSW = SSW / \\(n - k\\) |         |\n",
    "| Total                | SST            | \\(n - 1\\)          |             |         |\n",
    "\n",
    "  Where:\n",
    "  - \\(k\\) = Number of groups\n",
    "  - \\(n\\) = Total number of observations\n",
    "\n",
    "### Example of Violations:\n",
    "- **Unequal Within-Group Variance**: If there is more variability within one group than others (heteroscedasticity), the F-ratio may be distorted, leading to incorrect conclusions.\n",
    "- **Non-Independence**: If observations within groups are not independent (e.g., repeated measures), the within-group variance will be underestimated, inflating the F-ratio.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The partitioning of variance in ANOVA is central to identifying whether the differences between group means are significant or due to random variation. It allows for the calculation of the F-statistic, which is used to test hypotheses about the group means, making it a fundamental concept in understanding the logic and results of ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786923b1-441e-48bd-9ae7-30e9facb797a",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ffec0-ba0c-4acb-9edf-a169c8af6629",
   "metadata": {},
   "source": [
    "1. Total Sum of Squares (SST):\n",
    "This represents the total variance in the data, which is the sum of the squared differences between each individual observation and the overall mean.\n",
    "𝑆\n",
    "𝑆\n",
    "𝑇\n",
    "=\n",
    "∑\n",
    "(\n",
    "Observation\n",
    "−\n",
    "Overall Mean\n",
    ")\n",
    "2\n",
    "SST=∑(Observation−Overall Mean) \n",
    "2\n",
    " \n",
    "2. Explained Sum of Squares (SSE) (Between-Group Sum of Squares):\n",
    "This measures the variation between the group means and the overall mean. It quantifies how much of the total variation is explained by the group differences.\n",
    "𝑆\n",
    "𝑆\n",
    "𝐸\n",
    "=\n",
    "∑\n",
    "(\n",
    "Group Mean\n",
    "−\n",
    "Overall Mean\n",
    ")\n",
    "2\n",
    "×\n",
    "Group Size\n",
    "SSE=∑(Group Mean−Overall Mean) \n",
    "2\n",
    " ×Group Size\n",
    "3. Residual Sum of Squares (SSR) (Within-Group Sum of Squares):\n",
    "This represents the variation within the groups, or the unexplained variance. It quantifies the random variability or noise within the data that is not explained by the group differences.\n",
    "𝑆\n",
    "𝑆\n",
    "𝑅\n",
    "=\n",
    "∑\n",
    "(\n",
    "Observation\n",
    "−\n",
    "Group Mean\n",
    ")\n",
    "2\n",
    "SSR=∑(Observation−Group Mean) \n",
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737f7107-80fc-4ab2-830c-eba1e84d01a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 471.6\n",
      "Explained Sum of Squares (SSE): 436.79999999999995\n",
      "Residual Sum of Squares (SSR): 34.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example data for three groups\n",
    "data = {\n",
    "    'Group': ['A']*5 + ['B']*5 + ['C']*5,\n",
    "    'Values': [23, 20, 22, 24, 25, 30, 32, 31, 29, 28, 35, 37, 34, 36, 38]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = df['Values'].mean()\n",
    "\n",
    "# Calculate group means\n",
    "group_means = df.groupby('Group')['Values'].mean()\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "df['Overall Deviation'] = df['Values'] - overall_mean\n",
    "SST = np.sum(df['Overall Deviation']**2)\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "df['Group Mean'] = df['Group'].map(group_means)\n",
    "df['Group Deviation'] = df['Group Mean'] - overall_mean\n",
    "SSE = np.sum(df['Group Deviation']**2)\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "df['Residual'] = df['Values'] - df['Group Mean']\n",
    "SSR = np.sum(df['Residual']**2)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total Sum of Squares (SST): {SST}\")\n",
    "print(f\"Explained Sum of Squares (SSE): {SSE}\")\n",
    "print(f\"Residual Sum of Squares (SSR): {SSR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53bb2a-7960-44fb-b4ce-f6e57a6785aa",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc7f5a-e37f-418b-b7a9-1e496636ae0b",
   "metadata": {},
   "source": [
    "Steps for Calculating Main and Interaction Effects\n",
    "Main Effects:\n",
    "Factor A: The effect of different levels of the first factor on the dependent variable, ignoring the second factor.\n",
    "Factor B: The effect of different levels of the second factor on the dependent variable, ignoring the first factor.\n",
    "Interaction Effect:\n",
    "The effect of both factors combined, i.e., whether the impact of one factor varies depending on the levels of the other factor.\n",
    "Python Libraries:\n",
    "We can use statsmodels and pandas to perform a two-way ANOVA and calculate the main and interaction effects.\n",
    "Example:\n",
    "Let's assume we have a dataset where we measure a response variable (e.g., plant growth) based on two factors:\n",
    "\n",
    "Factor A: Type of fertilizer (3 levels: Fertilizer A, Fertilizer B, Fertilizer C)\n",
    "Factor B: Amount of water (2 levels: Low, High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0b9e65-f057-4bc0-a02d-b14f89b8fc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sum_sq    df       F    PR(>F)\n",
      "C(Fertilizer)            93.000000   2.0  20.925  0.000122\n",
      "C(Water)                112.500000   1.0  50.625  0.000012\n",
      "C(Fertilizer):C(Water)    0.333333   2.0   0.075  0.928175\n",
      "Residual                 26.666667  12.0     NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data for two-way ANOVA\n",
    "data = {\n",
    "    'Fertilizer': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C']*2,\n",
    "    'Water': ['Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low',\n",
    "              'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High'],\n",
    "    'PlantGrowth': [12, 15, 14, 10, 13, 11, 9, 8, 7, 18, 20, 17, 16, 15, 19, 14, 13, 12]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model (including interaction)\n",
    "model = ols('PlantGrowth ~ C(Fertilizer) + C(Water) + C(Fertilizer):C(Water)', data=df).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)  # Type 2 ANOVA for main effects and interaction\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79469718-7057-4e72-bf75-8fee4ec8b55d",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963e70d-7b3a-40a0-85cb-4bc3d96771b5",
   "metadata": {},
   "source": [
    "When interpreting the results of a one-way ANOVA, the F-statistic and the p-value are critical in determining whether there are statistically significant differences between the group means. Here’s how you would interpret the results in this scenario:\n",
    "\n",
    "### Given:\n",
    "- **F-statistic = 5.23**\n",
    "- **p-value = 0.02**\n",
    "- **Common significance level (α) = 0.05**\n",
    "\n",
    "### Step-by-Step Interpretation:\n",
    "\n",
    "1. **Null and Alternative Hypotheses**:\n",
    "   - **Null Hypothesis (\\(H_0\\))**: There is **no difference** between the group means. In other words, any observed differences in the sample means are due to random chance.\n",
    "   - **Alternative Hypothesis (\\(H_a\\))**: At least one group mean is **significantly different** from the others, suggesting that the differences between group means are not due to random variation.\n",
    "\n",
    "2. **p-Value Interpretation**:\n",
    "   - The **p-value** represents the probability of obtaining an F-statistic at least as extreme as 5.23, assuming that the null hypothesis is true (i.e., there are no real differences between the groups).\n",
    "   - **p-value = 0.02** means there is a 2% chance of observing such a difference (or a more extreme one) purely due to random chance if the null hypothesis is true.\n",
    "   \n",
    "   Since the **p-value (0.02)** is less than the commonly used significance level **α = 0.05**, you **reject the null hypothesis**. This indicates that there is **evidence to suggest that at least one group mean is significantly different** from the others.\n",
    "\n",
    "3. **F-Statistic Interpretation**:\n",
    "   - The **F-statistic (5.23)** is the ratio of the **between-group variance** to the **within-group variance**. A larger F-statistic indicates that the between-group variability is relatively large compared to the within-group variability.\n",
    "   - In this case, the F-statistic of 5.23 suggests that the differences between the group means are large relative to the variability within the groups.\n",
    "\n",
    "4. **Conclusion**:\n",
    "   - Since the **p-value** is less than 0.05, we **reject the null hypothesis**. This implies that there is a statistically significant difference between the group means.\n",
    "   - However, the ANOVA test **does not tell you which specific groups are different from each other**. It only tells you that at least one group mean differs significantly. To determine which groups differ, you would need to conduct a **post-hoc test** (e.g., Tukey’s HSD test) to compare the groups pairwise.\n",
    "\n",
    "### Practical Interpretation:\n",
    "- The ANOVA results suggest that the independent variable (grouping factor) has a significant effect on the dependent variable. This means that the groups are not all the same, and there are real differences between at least some of the groups.\n",
    "  \n",
    "### Example Scenario:\n",
    "Suppose you're testing whether different types of diets (Diet A, Diet B, Diet C) result in different weight loss outcomes. A one-way ANOVA is conducted to compare the mean weight loss between the three diets.\n",
    "\n",
    "- The F-statistic of 5.23 and the p-value of 0.02 indicate that there is a statistically significant difference in weight loss between at least one pair of diets. However, to identify which diets differ, a post-hoc test would be needed.\n",
    "\n",
    "### Summary:\n",
    "- **F-statistic = 5.23** and **p-value = 0.02** suggest significant differences between the group means.\n",
    "- Since **p < 0.05**, you reject the null hypothesis and conclude that at least one group mean is significantly different.\n",
    "- To find out which groups differ specifically, you would conduct a **post-hoc test** (e.g., Tukey’s HSD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb19fa5-e212-40d2-80ce-94bdaecc2951",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f878d84-a01e-4056-8e66-0eab39f33ddd",
   "metadata": {},
   "source": [
    "In a **repeated measures ANOVA**, dealing with missing data is particularly important because each subject is measured multiple times, and missing values can cause issues with the analysis. There are several methods for handling missing data, each with its potential consequences. Let's explore these methods and their implications.\n",
    "\n",
    "### 1. **Common Methods for Handling Missing Data**:\n",
    "\n",
    "#### a. **Listwise Deletion (Complete Case Analysis)**:\n",
    "- **Description**: Exclude any subject who has missing data for any of the repeated measures.\n",
    "- **Consequences**:\n",
    "  - **Loss of Power**: You lose statistical power because you are reducing the sample size by removing subjects with missing data.\n",
    "  - **Bias**: If the missing data are not missing completely at random (MCAR), this method can introduce bias.\n",
    "  - **Simplicity**: This method is easy to implement but only works well when the amount of missing data is very small.\n",
    "\n",
    "#### b. **Pairwise Deletion**:\n",
    "- **Description**: Use all available data without excluding entire subjects. Only the specific missing values are excluded for individual comparisons.\n",
    "- **Consequences**:\n",
    "  - **Inconsistent Sample Sizes**: Different analyses may be based on different subsets of data, which can lead to inconsistencies.\n",
    "  - **Potential for Bias**: Similar to listwise deletion, if data are not MCAR, this method can lead to biased results.\n",
    "  - **Complexity**: Can be more complex to implement and interpret since different analyses may be based on different sets of data points.\n",
    "\n",
    "#### c. **Mean Imputation**:\n",
    "- **Description**: Replace missing values with the mean of the observed data for that variable.\n",
    "- **Consequences**:\n",
    "  - **Underestimation of Variability**: Imputing the mean artificially reduces variability in the data, which can bias the results and increase the Type I error rate (false positives).\n",
    "  - **Bias**: Mean imputation does not preserve the natural relationships in the data, and it can distort the results.\n",
    "\n",
    "#### d. **Last Observation Carried Forward (LOCF)**:\n",
    "- **Description**: For longitudinal or time-based data, replace the missing value with the last observed value for that subject.\n",
    "- **Consequences**:\n",
    "  - **Bias**: LOCF assumes that the subject’s condition has not changed since the last measurement, which can be unrealistic, leading to biased estimates.\n",
    "  - **Inappropriate for Repeated Measures**: This method is generally not recommended in repeated measures ANOVA because it can artificially smooth over important variations in the data over time.\n",
    "\n",
    "#### e. **Multiple Imputation (MI)**:\n",
    "- **Description**: Generate several possible values for each missing data point based on the observed data and average the results. This method accounts for the uncertainty around missing data.\n",
    "- **Consequences**:\n",
    "  - **More Accurate**: Multiple imputation preserves the variability in the data and typically leads to less bias compared to single imputation methods.\n",
    "  - **Complexity**: Requires specialized software and expertise. It involves creating multiple datasets with imputed values, performing the analysis on each dataset, and then combining the results.\n",
    "  - **Computationally Intensive**: Multiple imputation can be computationally expensive, especially with large datasets.\n",
    "\n",
    "#### f. **Maximum Likelihood Estimation (MLE)**:\n",
    "- **Description**: Estimate the parameters of the model based on the available data, without imputing missing values directly.\n",
    "- **Consequences**:\n",
    "  - **Efficient Use of Data**: MLE makes full use of the available data and tends to produce less biased estimates compared to other methods.\n",
    "  - **Assumptions**: MLE relies on the assumption that the data are missing at random (MAR), which may not always be the case.\n",
    "  - **Computational Complexity**: MLE can be more computationally demanding, especially with large datasets or complex models.\n",
    "\n",
    "### 2. **Consequences of Using Different Methods**:\n",
    "\n",
    "#### a. **Bias**:\n",
    "   - Some methods, such as **mean imputation** or **LOCF**, can introduce bias by making strong assumptions about the data (e.g., that the mean is a good estimate or that no changes occur over time).\n",
    "   - **Listwise deletion** or **pairwise deletion** can also introduce bias if the missing data are not MCAR (Missing Completely at Random). If the missingness is related to the outcome, excluding subjects with missing data may result in non-representative data.\n",
    "\n",
    "#### b. **Loss of Power**:\n",
    "   - **Listwise deletion** reduces the sample size, which reduces the statistical power of the repeated measures ANOVA, making it harder to detect real effects.\n",
    "   - In contrast, methods like **multiple imputation** and **MLE** make full use of the available data and tend to preserve statistical power.\n",
    "\n",
    "#### c. **Type I and Type II Errors**:\n",
    "   - Imputation methods that reduce variability (like mean imputation or LOCF) can increase the likelihood of **Type I errors** (false positives), leading you to incorrectly conclude that there is a significant effect.\n",
    "   - Conversely, excluding data (listwise deletion) can increase the likelihood of **Type II errors** (false negatives), where you fail to detect a real effect due to a reduced sample size.\n",
    "\n",
    "#### d. **Complexity**:\n",
    "   - Some methods, such as **multiple imputation** or **MLE**, require more sophisticated statistical knowledge and software implementation but provide more accurate and reliable results.\n",
    "   - **Listwise deletion** and **mean imputation** are simpler but can lead to incorrect conclusions if the assumptions behind the missing data are not met.\n",
    "\n",
    "### 3. **Best Practices**:\n",
    "\n",
    "- **Check Missing Data Patterns**: Before deciding on a method, it’s crucial to check whether the data are MCAR, MAR, or MNAR (Missing Not at Random). If data are missing completely at random (MCAR), simpler methods like listwise deletion can be acceptable. If data are MAR, more sophisticated methods like multiple imputation or MLE are better.\n",
    "  \n",
    "- **Consider the Assumptions**: Methods like multiple imputation or maximum likelihood tend to be more robust under different missing data assumptions but are also more complex.\n",
    "\n",
    "- **Avoid Simple Imputation**: Single imputation methods like mean imputation or LOCF should generally be avoided because they underestimate variability and can introduce bias.\n",
    "\n",
    "### Example Using Python:\n",
    "\n",
    "For handling missing data in repeated measures ANOVA using **Multiple Imputation**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ac0254-aefe-4c1a-ab5f-fcb41d853ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Anova\n",
      "=================================\n",
      "     F Value Num DF Den DF Pr > F\n",
      "---------------------------------\n",
      "Time  9.1255 2.0000 8.0000 0.0086\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# Example DataFrame with missing values\n",
    "data = {\n",
    "    'Subject': [1, 2, 3, 4, 5],\n",
    "    'Time1': [5, 3, 4, None, 5],\n",
    "    'Time2': [6, 2, None, 7, 6],\n",
    "    'Time3': [7, None, 6, 8, 7]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Multiple imputation\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "imputed_data = imputer.fit_transform(df.drop('Subject', axis=1))\n",
    "\n",
    "# Replace missing data with imputed values\n",
    "df_imputed = df.copy()\n",
    "df_imputed.iloc[:, 1:] = imputed_data\n",
    "\n",
    "# Reshape data for repeated measures ANOVA\n",
    "df_long = pd.melt(df_imputed, id_vars=['Subject'], value_vars=['Time1', 'Time2', 'Time3'],\n",
    "                  var_name='Time', value_name='Score')\n",
    "\n",
    "# Fit repeated measures ANOVA\n",
    "model = AnovaRM(df_long, 'Score', 'Subject', within=['Time']).fit()\n",
    "\n",
    "# Output results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d98863-aeea-4115-989a-0ca226b66955",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b5ed4-1531-4994-aa72-25049a320525",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after a significant ANOVA result to determine **which specific group means are significantly different** from each other. While ANOVA can tell you that there is a significant difference among the groups, it does not tell you **which groups** differ. Post-hoc tests help address this.\n",
    "\n",
    "### Common Post-Hoc Tests:\n",
    "\n",
    "1. **Tukey’s Honestly Significant Difference (HSD) Test**:\n",
    "   - **When to Use**: \n",
    "     - Use this when you have **equal sample sizes** in each group and you're comparing all possible pairs of means. It is a good all-purpose test for comparing multiple groups after a one-way or two-way ANOVA.\n",
    "   - **Purpose**: \n",
    "     - Tukey’s HSD controls the family-wise error rate (the probability of making at least one Type I error) and is widely used for pairwise comparisons of group means.\n",
    "   - **Example**: \n",
    "     - If you conduct a one-way ANOVA to test whether three different teaching methods lead to different student performance and find a significant F-statistic, you can use Tukey’s HSD to determine which specific teaching methods differ.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - **When to Use**:\n",
    "     - When you want to perform multiple pairwise comparisons, and you want a **conservative correction** to control for the increased risk of Type I errors. It is suitable for any test where you perform multiple comparisons, and it can be used with unequal sample sizes.\n",
    "   - **Purpose**:\n",
    "     - Bonferroni adjusts the p-values by dividing the significance level (α) by the number of comparisons to reduce the likelihood of false positives.\n",
    "   - **Example**: \n",
    "     - Suppose you compare the effects of five different diets on weight loss and find a significant ANOVA result. You could use Bonferroni correction to adjust for the multiple comparisons between the diet groups.\n",
    "\n",
    "3. **Scheffé Test**:\n",
    "   - **When to Use**:\n",
    "     - The Scheffé test is useful when you want to make **complex comparisons** (not just pairwise) between groups. It is also appropriate when your sample sizes are unequal.\n",
    "   - **Purpose**:\n",
    "     - This test is more conservative than Tukey’s HSD or Bonferroni, making it less likely to detect differences, but it allows for comparisons beyond just pairwise contrasts (e.g., comparing the mean of one group to the combined mean of two others).\n",
    "   - **Example**: \n",
    "     - In an experiment comparing the effects of four fertilizers on plant growth, if you wanted to compare the average growth of Fertilizers A and B combined to that of Fertilizers C and D, the Scheffé test would allow this.\n",
    "\n",
    "4. **Dunnett’s Test**:\n",
    "   - **When to Use**:\n",
    "     - Use this when you are comparing multiple treatment groups against a **single control group**.\n",
    "   - **Purpose**:\n",
    "     - Dunnett’s test controls for the Type I error rate and is more powerful than other post-hoc tests when the goal is to compare multiple treatments to a control rather than comparing all groups against each other.\n",
    "   - **Example**: \n",
    "     - If you have a control group and three different drug treatments and the ANOVA shows a significant difference, you would use Dunnett’s test to determine which drug treatments differ from the control.\n",
    "\n",
    "5. **Fisher’s Least Significant Difference (LSD) Test**:\n",
    "   - **When to Use**:\n",
    "     - Use this when you have **a priori** hypotheses and you expect that some groups will differ from others. It does not control for family-wise error rate, so it is less conservative and can lead to more Type I errors.\n",
    "   - **Purpose**:\n",
    "     - Fisher’s LSD allows pairwise comparisons without adjusting for multiple comparisons. It is only recommended if you are confident that there are true differences between groups.\n",
    "   - **Example**: \n",
    "     - After finding a significant ANOVA result for different teaching methods, Fisher’s LSD could be used to test pairwise comparisons, but with the risk of inflating the Type I error rate.\n",
    "\n",
    "6. **Holm-Bonferroni Method**:\n",
    "   - **When to Use**:\n",
    "     - This is a more **powerful alternative** to the Bonferroni correction. It is used when you need to control for multiple comparisons but want a less conservative approach than Bonferroni.\n",
    "   - **Purpose**:\n",
    "     - Holm-Bonferroni controls the family-wise error rate but does so in a stepwise manner, making it more powerful than the Bonferroni correction.\n",
    "   - **Example**: \n",
    "     - You’ve run a one-way ANOVA comparing five different diet interventions and want to perform post-hoc tests with more power than Bonferroni. The Holm-Bonferroni method would adjust the significance levels more flexibly.\n",
    "\n",
    "### Example Scenario:\n",
    "\n",
    "#### **Scenario**:\n",
    "You conduct a study to compare the average test scores of students in four different classrooms that use different teaching methods (Method A, B, C, and D). You run a one-way ANOVA and find a significant F-statistic, meaning that there is a difference in test scores between at least one pair of teaching methods.\n",
    "\n",
    "#### **Post-Hoc Test Application**:\n",
    "Since you want to find out **which specific teaching methods lead to different test scores**, you choose a post-hoc test:\n",
    "- **Tukey’s HSD** would be appropriate here because it allows for **all pairwise comparisons** of group means, and the sample sizes are equal across the groups.\n",
    "\n",
    "If you instead had a **control group** (e.g., students taught with no specific method) and you were interested in comparing each teaching method against the control, you would use **Dunnett’s test**.\n",
    "\n",
    "### Summary of Post-Hoc Tests:\n",
    "| Post-Hoc Test          | When to Use                                              | Strengths                                             | Weaknesses                                               |\n",
    "|------------------------|----------------------------------------------------------|-------------------------------------------------------|----------------------------------------------------------|\n",
    "| **Tukey's HSD**         | Pairwise comparisons with equal sample sizes             | Controls Type I error; good for general pairwise tests | Assumes equal sample sizes                               |\n",
    "| **Bonferroni Correction** | Conservative correction for multiple comparisons        | Simple to apply; highly conservative                   | Reduces power; may lead to Type II errors                 |\n",
    "| **Scheffé Test**        | Comparing groups in complex ways (beyond pairwise)       | Flexible; allows for complex comparisons               | Very conservative; less power                            |\n",
    "| **Dunnett’s Test**      | Comparing multiple groups to a single control            | Controls Type I error well in comparisons to control   | Not suitable for all-pairwise comparisons                 |\n",
    "| **Fisher’s LSD**        | When you have specific hypotheses about group differences | Simple to apply; powerful when prior hypotheses exist  | Does not control for multiple comparisons; increased Type I error risk |\n",
    "| **Holm-Bonferroni**     | More flexible, less conservative than Bonferroni         | Controls family-wise error but retains more power      | Still more conservative than other methods               |\n",
    "\n",
    "### Conclusion:\n",
    "Post-hoc tests are essential when you need to explore **which groups differ after a significant ANOVA** result. The choice of post-hoc test depends on the **research design**, **number of comparisons**, and the **desired balance** between controlling Type I errors and maintaining statistical power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e9b2db-8c60-4054-8f30-24e5b34fcded",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718801e2-6c2f-463a-aa7b-8a5735782ed0",
   "metadata": {},
   "source": [
    "To perform a one-way ANOVA in Python to compare the mean weight loss across three different diets (A, B, and C), we will follow these steps:\n",
    "\n",
    "1. Simulate or use given weight loss data for participants on each diet.\n",
    "2. Perform the one-way ANOVA using Python's `scipy.stats` or `statsmodels` package.\n",
    "3. Report the F-statistic and p-value.\n",
    "4. Interpret the results.\n",
    "\n",
    "### Step 1: Generate or use weight loss data\n",
    "\n",
    "Let’s assume the weight loss data (in kg) for the 50 participants across three diets looks like this:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Simulate some data for weight loss for diets A, B, and C\n",
    "np.random.seed(42)  # for reproducibility\n",
    "diet_A = np.random.normal(loc=5, scale=1.5, size=17)  # 17 participants on diet A\n",
    "diet_B = np.random.normal(loc=6, scale=1.2, size=17)  # 17 participants on diet B\n",
    "diet_C = np.random.normal(loc=4, scale=1.4, size=16)  # 16 participants on diet C\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'weight_loss': np.concatenate([diet_A, diet_B, diet_C]),\n",
    "    'diet': ['A'] * 17 + ['B'] * 17 + ['C'] * 16\n",
    "})\n",
    "```\n",
    "\n",
    "### Step 2: Conduct a one-way ANOVA\n",
    "\n",
    "We will use the `scipy.stats.f_oneway` function to conduct the ANOVA.\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {F_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "```\n",
    "\n",
    "### Step 3: Report F-statistic and p-value\n",
    "\n",
    "This code will print the F-statistic and p-value. Let’s assume the output is as follows:\n",
    "\n",
    "```\n",
    "F-statistic: 8.236\n",
    "p-value: 0.00123\n",
    "```\n",
    "\n",
    "### Step 4: Interpretation of Results\n",
    "\n",
    "- **F-statistic**: The F-statistic is 8.236, which indicates the ratio of variance between the diet groups to the variance within the groups.\n",
    "- **p-value**: The p-value is 0.00123.\n",
    "\n",
    "#### Interpretation:\n",
    "Since the **p-value (0.00123) is less than the significance level (0.05)**, we reject the null hypothesis. This means that there is a **significant difference** in mean weight loss between at least two of the diets. However, the ANOVA test does not tell us which specific diets differ. To determine that, we would need to perform a **post-hoc test**, such as Tukey’s HSD.\n",
    "\n",
    "### Full Python Code Example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Simulate some data for weight loss for diets A, B, and C\n",
    "np.random.seed(42)  # for reproducibility\n",
    "diet_A = np.random.normal(loc=5, scale=1.5, size=17)  # 17 participants on diet A\n",
    "diet_B = np.random.normal(loc=6, scale=1.2, size=17)  # 17 participants on diet B\n",
    "diet_C = np.random.normal(loc=4, scale=1.4, size=16)  # 16 participants on diet C\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {F_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Interpretation:\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the diets.\")\n",
    "```\n",
    "\n",
    "This code generates the data, conducts the ANOVA, and prints the F-statistic, p-value, and an interpretation of whether there is a significant difference between the diets based on the p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf68cf-3feb-4d7a-a447-f21f514e16ab",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c214cc-a902-42a2-8ddd-fb3bfe937205",
   "metadata": {},
   "source": [
    "To conduct a two-way ANOVA in Python for this scenario (comparing the time taken to complete a task using three different software programs and considering the interaction between software programs and employee experience level), we'll follow these steps:\n",
    "\n",
    "1. Simulate or use given data for task completion times based on the software program and employee experience level (novice vs. experienced).\n",
    "2. Perform a two-way ANOVA using Python (`statsmodels`).\n",
    "3. Report the F-statistics and p-values for the main effects (software program and experience level) and interaction effects.\n",
    "4. Interpret the results.\n",
    "\n",
    "### Step 1: Generate or Use Task Completion Time Data\n",
    "\n",
    "Assume we have 30 employees, with 15 novices and 15 experienced workers, randomly assigned to use one of three software programs (A, B, or C). We'll simulate the data for task completion times based on these factors.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Simulate task completion time data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Novices\n",
    "novice_A = np.random.normal(loc=25, scale=5, size=5)  # 5 novice employees using Program A\n",
    "novice_B = np.random.normal(loc=30, scale=6, size=5)  # 5 novice employees using Program B\n",
    "novice_C = np.random.normal(loc=28, scale=4, size=5)  # 5 novice employees using Program C\n",
    "\n",
    "# Experienced\n",
    "exp_A = np.random.normal(loc=20, scale=4, size=5)  # 5 experienced employees using Program A\n",
    "exp_B = np.random.normal(loc=22, scale=5, size=5)  # 5 experienced employees using Program B\n",
    "exp_C = np.random.normal(loc=18, scale=3, size=5)  # 5 experienced employees using Program C\n",
    "\n",
    "# Combine the data into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'completion_time': np.concatenate([novice_A, novice_B, novice_C, exp_A, exp_B, exp_C]),\n",
    "    'software': ['A'] * 5 + ['B'] * 5 + ['C'] * 5 + ['A'] * 5 + ['B'] * 5 + ['C'] * 5,\n",
    "    'experience': ['novice'] * 15 + ['experienced'] * 15\n",
    "})\n",
    "\n",
    "# Display the first few rows of data\n",
    "print(data.head())\n",
    "```\n",
    "\n",
    "### Step 2: Perform a Two-Way ANOVA Using Python\n",
    "\n",
    "We will use the `statsmodels` package to perform the two-way ANOVA and test for both main effects (software program and experience level) and interaction effects (software * experience).\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create the two-way ANOVA model\n",
    "model = ols('completion_time ~ C(software) + C(experience) + C(software):C(experience)', data=data).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_table)\n",
    "```\n",
    "\n",
    "### Step 3: Report F-Statistics and p-Values\n",
    "\n",
    "Assume the ANOVA table looks like this:\n",
    "\n",
    "```\n",
    "                              sum_sq   df          F        PR(>F)\n",
    "C(software)              452.333333    2   8.264706   0.002351\n",
    "C(experience)            686.533333    1  25.030612   0.000014\n",
    "C(software):C(experience) 96.800000    2   1.765306   0.194519\n",
    "Residual                 659.200000   24        NaN        NaN\n",
    "```\n",
    "\n",
    "- **F-statistic for software (C(software))**: 8.26, p-value = 0.0024\n",
    "- **F-statistic for experience (C(experience))**: 25.03, p-value = 0.000014\n",
    "- **F-statistic for interaction (C(software):C(experience))**: 1.77, p-value = 0.1945\n",
    "\n",
    "### Step 4: Interpretation of Results\n",
    "\n",
    "1. **Software (C(software))**:\n",
    "   - The p-value for the **main effect of software program** is 0.0024, which is less than the significance level of 0.05.\n",
    "   - **Conclusion**: There is a **significant difference** in the average task completion time between the three software programs.\n",
    "\n",
    "2. **Experience Level (C(experience))**:\n",
    "   - The p-value for the **main effect of experience level** is 0.000014, which is much less than 0.05.\n",
    "   - **Conclusion**: There is a **significant difference** in the average task completion time between novice and experienced employees.\n",
    "\n",
    "3. **Interaction (C(software):C(experience))**:\n",
    "   - The p-value for the **interaction effect** between software program and experience level is 0.1945, which is greater than 0.05.\n",
    "   - **Conclusion**: There is **no significant interaction** between software program and employee experience level. This means that the difference in task completion time between software programs does not depend on whether the employee is novice or experienced.\n",
    "\n",
    "### Full Python Code Example\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Simulate task completion time data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Novices\n",
    "novice_A = np.random.normal(loc=25, scale=5, size=5)\n",
    "novice_B = np.random.normal(loc=30, scale=6, size=5)\n",
    "novice_C = np.random.normal(loc=28, scale=4, size=5)\n",
    "\n",
    "# Experienced\n",
    "exp_A = np.random.normal(loc=20, scale=4, size=5)\n",
    "exp_B = np.random.normal(loc=22, scale=5, size=5)\n",
    "exp_C = np.random.normal(loc=18, scale=3, size=5)\n",
    "\n",
    "# Combine the data into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'completion_time': np.concatenate([novice_A, novice_B, novice_C, exp_A, exp_B, exp_C]),\n",
    "    'software': ['A'] * 5 + ['B'] * 5 + ['C'] * 5 + ['A'] * 5 + ['B'] * 5 + ['C'] * 5,\n",
    "    'experience': ['novice'] * 15 + ['experienced'] * 15\n",
    "})\n",
    "\n",
    "# Create the two-way ANOVA model\n",
    "model = ols('completion_time ~ C(software) + C(experience) + C(software):C(experience)', data=data).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_table)\n",
    "```\n",
    "\n",
    "### Conclusion:\n",
    "- The software program and employee experience level **independently** influence task completion time.\n",
    "- There is **no significant interaction** between software program and experience level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb44981-2c46-48de-9549-edfa10f8f989",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b216eb3-6817-4a60-bd32-4fb2598282c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -4.108723928204809\n",
      "P-value: 8.261945608702613e-05\n",
      "Cohen's d: 0.8217447856409618\n",
      "There is a significant difference between the test scores of the two groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Simulate test scores for control and experimental groups\n",
    "np.random.seed(42)\n",
    "\n",
    "# Control group (traditional teaching method)\n",
    "control_scores = np.random.normal(loc=75, scale=10, size=50)  # Mean = 75, SD = 10\n",
    "\n",
    "# Experimental group (new teaching method)\n",
    "experimental_scores = np.random.normal(loc=80, scale=10, size=50)  # Mean = 80, SD = 10\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'score': np.concatenate([control_scores, experimental_scores]),\n",
    "    'group': ['Control'] * 50 + ['Experimental'] * 50\n",
    "})\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Output the results\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Calculate Cohen's d\n",
    "mean_control = np.mean(control_scores)\n",
    "mean_experimental = np.mean(experimental_scores)\n",
    "std_control = np.std(control_scores, ddof=1)\n",
    "std_experimental = np.std(experimental_scores, ddof=1)\n",
    "\n",
    "pooled_std = np.sqrt(((std_control**2) + (std_experimental**2)) / 2)\n",
    "cohens_d = (mean_experimental - mean_control) / pooled_std\n",
    "\n",
    "print(f\"Cohen's d: {cohens_d}\")\n",
    "\n",
    "# Interpretation of the results\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the test scores of the two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the test scores of the two groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda46989-cf96-43e8-ad47-3f143b0b7b1d",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74d9d7c5-4f3b-4e51-bc06-64f13c91ba9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store  9.6931 2.0000 58.0000 0.0002\n",
      "===================================\n",
      "\n",
      "Comparison between Store_A and Store_B -> T-statistic: -4.0584, P-value: 0.0003\n",
      "Comparison between Store_A and Store_C -> T-statistic: -3.2560, P-value: 0.0029\n",
      "Comparison between Store_B and Store_C -> T-statistic: 1.3634, P-value: 0.1832\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy import stats\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate daily sales data for three stores over 30 days\n",
    "days = 30\n",
    "store_A_sales = np.random.normal(loc=200, scale=20, size=days)\n",
    "store_B_sales = np.random.normal(loc=220, scale=25, size=days)\n",
    "store_C_sales = np.random.normal(loc=210, scale=15, size=days)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Day': np.arange(1, days + 1),\n",
    "    'Store_A': store_A_sales,\n",
    "    'Store_B': store_B_sales,\n",
    "    'Store_C': store_C_sales\n",
    "})\n",
    "\n",
    "# Reshape the data into long format\n",
    "data_long = pd.melt(data, id_vars=['Day'], value_vars=['Store_A', 'Store_B', 'Store_C'],\n",
    "                    var_name='Store', value_name='Sales')\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "anova_results = AnovaRM(data_long, 'Sales', 'Day', within=['Store']).fit()\n",
    "\n",
    "# Output the ANOVA table\n",
    "print(anova_results)\n",
    "\n",
    "# Conduct pairwise comparisons using t-tests\n",
    "results = {}\n",
    "stores = ['Store_A', 'Store_B', 'Store_C']\n",
    "\n",
    "for i in range(len(stores)):\n",
    "    for j in range(i + 1, len(stores)):\n",
    "        t_stat, p_val = stats.ttest_rel(data[stores[i]], data[stores[j]])\n",
    "        results[(stores[i], stores[j])] = (t_stat, p_val)\n",
    "\n",
    "# Output pairwise t-test results\n",
    "for (store1, store2), (t_stat, p_val) in results.items():\n",
    "    print(f\"Comparison between {store1} and {store2} -> T-statistic: {t_stat:.4f}, P-value: {p_val:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
